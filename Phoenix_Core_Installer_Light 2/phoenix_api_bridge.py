from flask import Flask, request, jsonify
import requests
import socket
import os
import openai

app = Flask(__name__)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
OLLAMA_URL = "http://127.0.0.1:11434/api/generate"
current_model = "qwen3:8b"
openai.api_key = "sk-test_fakekey_1234567890abcdef"

# üîç –ü–æ–∏—Å–∫ —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –ø–æ—Ä—Ç–∞
def find_free_port(start_port=8085, max_tries=20):
    port = start_port
    for _ in range(max_tries):
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
            try:
                s.bind(("127.0.0.1", port))
                return port
            except OSError:
                port += 1
    raise RuntimeError("–ù–µ—Ç —Å–≤–æ–±–æ–¥–Ω—ã—Ö –ø–æ—Ä—Ç–æ–≤!")

# üì° –ó–∞–ø—Ä–æ—Å –≤ ChatGPT, –µ—Å–ª–∏ Ollama –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç
def fallback_to_chatgpt(prompt):
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "–¢—ã ‚Äî —Ä–∞–∑—É–º –§–µ–Ω–∏–∫—Å–∞. –û—Ç–≤–µ—á–∞–π –≥–ª—É–±–æ–∫–æ, —è—Å–Ω–æ –∏ –ø–æ –¥–µ–ª—É."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7
        )
        return response['choices'][0]['message']['content'].strip()
    except Exception as e:
        return f"[–û—à–∏–±–∫–∞ ChatGPT]: {str(e)}"

# üöÄ –û—Å–Ω–æ–≤–Ω–æ–π –º–∞—Ä—à—Ä—É—Ç –¥–ª—è Streamlit
@app.route("/chat", methods=["POST"])
def chat():
    try:
        data = request.get_json(force=True)
        user_input = data.get("user_input", "")

        if not user_input:
            return jsonify({"error": "–ü—É—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å"}), 400

        answer = ""
        try:
            response = requests.post(OLLAMA_URL, json={
                "model": current_model,
                "prompt": user_input
            }, stream=True, timeout=60)

            for line in response.iter_lines():
                if line:
                    try:
                        chunk = line.decode("utf-8")
                        if '"response":"' in chunk:
                            part = chunk.split('"response":"')[1].split('"')[0]
                            answer += part
                    except:
                        continue
        except Exception as e:
            answer = f"[–û—à–∏–±–∫–∞ Ollama]: {str(e)}"

        # ‚õë –ï—Å–ª–∏ Ollama –ø—Ä–æ–º–æ–ª—á–∞–ª ‚Äî –ø–æ–¥–∫–ª—é—á–∞–µ–º ChatGPT
        if not answer.strip() or answer.startswith("[–û—à–∏–±–∫–∞"):
            answer = fallback_to_chatgpt(user_input)

        return jsonify({"response": answer})

    except Exception as e:
        return jsonify({"error": f"–û—à–∏–±–∫–∞: {str(e)}"}), 500

# üõ† –†—É—á–Ω–æ–π –º–∞—Ä—à—Ä—É—Ç
@app.route("/ask", methods=["POST"])
def ask():
    try:
        data = request.get_json(force=True)
        prompt = data.get("prompt", "")

        if not prompt:
            return jsonify({"error": "–ü—É—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å"}), 400

        answer = ""
        try:
            response = requests.post(OLLAMA_URL, json={
                "model": current_model,
                "prompt": prompt
            }, stream=True, timeout=60)

            for line in response.iter_lines():
                if line:
                    try:
                        chunk = line.decode("utf-8")
                        if '"response":"' in chunk:
                            part = chunk.split('"response":"')[1].split('"')[0]
                            answer += part
                    except:
                        continue
        except Exception as e:
            answer = f"[–û—à–∏–±–∫–∞ Ollama]: {str(e)}"

        if not answer.strip() or answer.startswith("[–û—à–∏–±–∫–∞"):
            answer = fallback_to_chatgpt(prompt)

        return jsonify({"response": answer})

    except Exception as e:
        return jsonify({"error": f"–û—à–∏–±–∫–∞: {str(e)}"}), 500

# üîÑ –°–º–µ–Ω–∞ –º–æ–¥–µ–ª–∏
@app.route("/set_model", methods=["POST"])
def set_model():
    global current_model
    data = request.json
    model = data.get("model")
    if not model:
        return jsonify({"error": "–ú–æ–¥–µ–ª—å –Ω–µ —É–∫–∞–∑–∞–Ω–∞"}), 400

    current_model = model
    return jsonify({"status": "OK", "model": current_model})

# üåê –ö–æ—Ä–Ω–µ–≤–æ–π –º–∞—Ä—à—Ä—É—Ç
@app.route("/")
def root():
    return jsonify({"status": "Phoenix API Bridge —Ä–∞–±–æ—Ç–∞–µ—Ç", "model": current_model})

# üß† –ó–∞–ø—É—Å–∫
if __name__ == "__main__":
    free_port = find_free_port(8085)
    print(f"[API Bridge] –ó–∞–ø—É—Å–∫ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –º–æ—Å—Ç–∞ –§–µ–Ω–∏–∫—Å–∞ –Ω–∞ –ø–æ—Ä—Ç—É {free_port}")
    print(f"–§–µ–Ω–∏–∫—Å –≥–æ—Ç–æ–≤ –ø—Ä–∏–Ω–∏–º–∞—Ç—å –∑–∞–ø—Ä–æ—Å—ã –Ω–∞ http://127.0.0.1:{free_port}")
    app.run(host="127.0.0.1", port=free_port)
